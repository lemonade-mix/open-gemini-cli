# open-gemini-cli Roadmap

## Goals

1. Multi-provider support - Use any LLM, not just Gemini
2. Local LLM integration - Run completely offline
3. Simplified auth - No mandatory Google OAuth

## Done

- OpenAI provider support
- Anthropic Claude support
- Local LLM support (MLX, llama.cpp, vLLM)
- JSON-configurable provider system
- Removed Google OAuth requirement

## Next

- Better local model configuration
- Model switching within sessions
- Provider-specific optimizations

## Credits

Based on [gemini-cli](https://github.com/google-gemini/gemini-cli) by Google.
